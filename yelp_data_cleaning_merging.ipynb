{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring business file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_json('yelp_data/business.json', lines=True)\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = open, 0 = closed\n",
    "df_b = df_b[df_b['is_open']==1]\n",
    "#df_b = df_b[df_b['state']=='AZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring cities\n",
    "df_b.city.value_counts().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b =(df_b.loc[df_b['city'].isin(['Las Vegas', 'Phoenix','Charlotte','Scottsdale'  ])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns\n",
    "drop_columns = ['hours','is_open']\n",
    "df_b = df_b.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting resturants\n",
    "business_resturants = df_b[df_b['categories'].str.contains(\n",
    "              'Restaurants',\n",
    "              case=False, na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_resturants.head(2)\n",
    "business_resturants.name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in str(col):\n",
    "#     print(business_resturants['categories'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants.categories.value_counts().sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regex to remove Restaurants\n",
    "import re\n",
    "#removing Resturants, \n",
    "business_resturants['categories'] = [re.sub(r'Restaurants\\,\\s', \"\", x) for x in business_resturants['categories']]\n",
    "#removing , Resturants\n",
    "business_resturants['categories'] = [re.sub(r',\\ \\bRestaurants', \"\", x) for x in business_resturants['categories']]\n",
    " #changing American (Traditional) and American (New) to American\n",
    "business_resturants['categories'] = [re.sub(r'American\\s\\(\\w*\\)', \"American\", x) for x in business_resturants['categories']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = ['Pizza', \n",
    "#               'Italian', \n",
    "#               'Tex-Mex', \n",
    "#               'Seafood', \n",
    "#               'Mexican', \n",
    "#               'Thai', \n",
    "#               'Breakfast & Brunch', \n",
    "#               'Burgers', \n",
    "#               'Bars', \n",
    "#               'Juice Bars & Smoothies', \n",
    "#               'Coffee & Tea', \n",
    "#               'American (Traditional)',\n",
    "#               'American (New)',\n",
    "#               'Sandwiches',\n",
    "#               'Salad',\n",
    "#               'Chinese']\n",
    "\n",
    "# newFeatures2 = pd.DataFrame(0, index=np.arange(len(resDataFeatures)), columns=categories)\n",
    "\n",
    "# for i in range(0,len(resDataFeatures)):\n",
    "#     for x, j in enumerate(categories):\n",
    "#         if j in resDataFeatures['categories'][i]:\n",
    "#             newFeatures2.set_value(i, j, 1)\n",
    "\n",
    "# newFeatures2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode = business_resturants.assign(categories = business_resturants.categories\n",
    "                         .str.split(', ')).explode('categories')\n",
    "df_explode.categories.value_counts().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode[df_explode.categories=='Food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants.categories.value_counts().sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#business_resturants['categories'] =business_resturants['categories'].str.replace(',','')\n",
    "#creating new column by extracting Fast Food from string of words\n",
    "business_resturants['new_categories']= business_resturants['categories'].str.extract(r'(Fast Food)')\n",
    "# Bringing rest of the original categories to fill nan in new categor column\n",
    "business_resturants.new_categories.fillna(business_resturants.categories, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants.new_categories.value_counts().sort_values(ascending=False).head(50)\n",
    "#changing order\n",
    "business_resturants['new_categories'] = [re.sub(\"(Pizza, Italian)\", \"Italian, Pizza\", x) for x in business_resturants['new_categories']]\n",
    "business_resturants['new_categories'] = [re.sub(\"(Food, Mexican)|(Mexican, Food)\", \"Mexican\", x) for x in business_resturants['new_categories']]\n",
    "business_resturants['new_categories'] = [re.sub(\"(Seafood, Mexican)\", \"Mexican, Seafood\", x) for x in business_resturants['new_categories']]\n",
    "business_resturants.new_categories.value_counts().sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants.new_categories.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "from pandas.io.json import json_normalize \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants =business_resturants[business_resturants['attributes'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting price range from nested attribute column\n",
    "idx = business_resturants.index[business_resturants.attributes.notna()]\n",
    "price_range = pd.json_normalize(business_resturants.attributes.dropna().tolist())['RestaurantsPriceRange2']\n",
    "price_range.index =idx\n",
    "business_resturants['price_range'] =price_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting ambience from nested Json column attibutes\n",
    "idx = business_resturants.index[business_resturants.attributes.notna()]\n",
    "ambience = pd.json_normalize(business_resturants.attributes.dropna().tolist())['Ambience']\n",
    "ambience.index =idx\n",
    "business_resturants['ambience'] = ambience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = business_resturants.index[business_resturants.attributes.notna()]\n",
    "# romantic = pd.json_normalize(business_resturants.attributes.dropna().tolist(), max_level = 1) #max_level to look at nested level\n",
    "# romantic.index =idx\n",
    "# business_resturants['romantic'] = romantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(business_resturants.loc[11, 'attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants.head().ambience.dropna().apply(lambda x: ast.literal_eval(x)['romantic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ambience(x,ambience):\n",
    "    try:\n",
    "        return(ast.literal_eval(x)[ambience])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants['romantic'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'romantic'))\n",
    "business_resturants['intimate'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'intimate'))\n",
    "business_resturants['touristy'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'touristy'))\n",
    "business_resturants['hipster'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'hipster'))\n",
    "business_resturants['divey'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'divey'))\n",
    "business_resturants['classy'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'classy'))\n",
    "business_resturants['trendy'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'trendy'))\n",
    "business_resturants['upscale'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'upscale'))\n",
    "business_resturants['casual'] = business_resturants.ambience.apply(lambda x: get_ambience(x,'casual'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing True or False to 1&0\n",
    "business_resturants.replace(False,0, inplace =True)\n",
    "business_resturants.replace(True,1, inplace =True)\n",
    "#df[['cl1','cl2']]=(fault_diagnostics[['cl1','cl2']]=='True').astype(int)\n",
    "#test.replace(False, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns\n",
    "business_resturants = business_resturants.drop(['attributes','ambience', 'categories' ], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking key for dictionary\n",
    "# def getList(dict): \n",
    "#     return dict.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants =business_resturants.replace(to_replace ='None', value =np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants['price_range'] =  pd.to_numeric(business_resturants[\"price_range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_list =['price_range', 'romantic', 'intimate' , 'touristy' , 'hipster', 'divey', 'classy', \n",
    "              'trendy', 'upscale', 'casual'   ]\n",
    "# Impute missing\n",
    "business_resturants = business_resturants.fillna(business_resturants.groupby('name')[impute_list].transform('median'))\n",
    "business_resturants=business_resturants.dropna(subset =impute_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cat(x):\n",
    "    if x in ('Fast Food'):\n",
    "        category = 1\n",
    "    else:\n",
    "        category = 0\n",
    "    return category\n",
    "\n",
    "business_resturants['category'] = business_resturants['new_categories'].apply (binary_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating business_resturants\n",
    "business_resturants.to_csv('yelp_data/business_resturants.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTITY TyPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(str(business_resturants['new_categories']))\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain('NORP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extarcting entity type from the dataframe\n",
    "\n",
    "def extract_category(text):\n",
    "    for ent in nlp(text).ents:\n",
    "        if ent.label_ == 'NORP':\n",
    "            return(ent.text)\n",
    "#         if ent.label_ =='NORP':\n",
    "#             return(ent.text)\n",
    "        \n",
    "        else:\n",
    "            return (text)\n",
    "        \n",
    "            \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(df):\n",
    "    business_resturants['ethnic_categories'] = business_resturants['new_categories'].apply(extract_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_column(business_resturants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df =business_resturants[business_resturants.new_categories.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants['new_categories'].value_counts(dropna =False).sort_values(ascending=False).head(30)\n",
    "# .plot(kind ='barh')\n",
    "# plt.title('Ethnic Resturant Value Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants.name.value_counts(dropna=False).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants[business_resturants.name=='Taco Bell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants[business_resturants.new_categories==\"Event Planning & Services\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the restaurants  less then 2\n",
    "new =business_resturants.name.value_counts().reset_index(name=\"count\").query(\"count < 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.countplot(business_resturants['stars'], ax=ax)\n",
    "plt.title('Star Ratings');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"stars\", col=\"city\",\n",
    "                data=business_resturants, kind=\"count\",\n",
    "                height= 5, aspect=.9);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_explode.categories.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find category with resturant\n",
    "# df_explode[df_explode.categories.str.contains('Restaurants',\n",
    "#                       case=True,na=False)].categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging business file with review and user info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_resturants = pd.read_csv('yelp_data/business_resturants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_json_path  = 'yelp_data/review.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_json_path  = 'yelp_data/review.json'\n",
    "size = 1000000\n",
    "review = pd.read_json(review_json_path, lines=True,\n",
    "                      dtype={'review_id':str,'user_id':str,\n",
    "                             'business_id':str,'stars':int,\n",
    "                             'date':str,'text':str,'useful':int,\n",
    "                             'funny':int,'cool':int},\n",
    "                      chunksize=size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging business file and review file\n",
    "chunk_list = []\n",
    "for chunk_review in review:\n",
    "    # Drop columns that aren't needed\n",
    "    chunk_review = chunk_review.drop(['useful','funny','cool'], axis=1)\n",
    "    # Renaming column name to avoid conflict with business overall star rating\n",
    "    chunk_review = chunk_review.rename(columns={'stars': 'review_stars'})\n",
    "    # Inner merge with edited business file so only reviews related to the business remain\n",
    "    chunk_merged = pd.merge(business_resturants, chunk_review, on='business_id', how='inner')\n",
    "    # Show feedback on progress\n",
    "    print(f\"{chunk_merged.shape[0]} out of {size:,} related reviews\")\n",
    "    chunk_list.append(chunk_merged)\n",
    "# After trimming down the review file, concatenate all relevant data back to one dataframe\n",
    "business_review = pd.concat(chunk_list, ignore_index=True, join='outer', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_review.to_csv('yelp_data/yelp_merged.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_merged =pd.read_csv('yelp_data/yelp_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_merged.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_merged[yelp_merged.state ==\"NM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_json_path = 'yelp_data/user.json'\n",
    "size = 1000000\n",
    "user = pd.read_json(user_json_path, lines=True,\n",
    "                      dtype={'user_id':str,\n",
    "                             'name':str,'review_count':int,'yelping_since':str,'friends':str,'useful':int,\n",
    "                             'funny':int,'cool':int,'fans':int, 'elite':int,'average_stars':float,'compliment_hot':int,\n",
    "                             'compliment_more':int, 'compliment_profile':int,'compliment_cute':int,'compliment_list':int,\n",
    "                             'compliment_note':int, 'compliment_plain':int, 'compliment_cool':int,'compliment_funny':int,\n",
    "                             'compliment_funny':int, 'compliment_writer':int,'compliment_photos': int\n",
    "                            },\n",
    "                      chunksize=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging user data\n",
    "chunk_list = []\n",
    "for chunk_user in user:\n",
    "    # Drop columns that aren't needed\n",
    "    chunk_user = chunk_user.drop(['name','friends','useful', 'funny','cool','fans', 'elite','compliment_hot',\n",
    "                             'compliment_more', 'compliment_profile','compliment_cute','compliment_list',\n",
    "                             'compliment_note', 'compliment_plain', 'compliment_cool','compliment_funny',\n",
    "                             'compliment_funny', 'compliment_writer','compliment_photos', 'yelping_since'], axis=1)\n",
    "    # Renaming column name to avoid conflict with business/review overall star rating\n",
    "    chunk_user = chunk_user.rename(columns={'average_stars': 'user__average_stars'})\n",
    "    # Inner merge with edited business file so only reviews related to the business remain\n",
    "    chunk_merged = pd.merge(yelp_merged, chunk_user, on='user_id', how='inner')\n",
    "    # Show feedback on progress\n",
    "    print(f\"{chunk_merged.shape[0]} out of {size:,} related users\")\n",
    "    chunk_list.append(chunk_merged)\n",
    "#creating a folder with chunks of merged file\n",
    "\n",
    "# After trimming down the review file, concatenate all relevant data back to one dataframe\n",
    "user_merged = pd.concat(chunk_list, ignore_index=True, join='outer', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating a folder in pc with chunks of merged file rather than appending the list\n",
    "# chunk_list = []\n",
    "# i=1\n",
    "# for chunk_user in user:\n",
    "#     # Drop columns that aren't needed\n",
    "#     chunk_user = chunk_user.drop(['name','friends','useful', 'funny','cool','fans', 'elite','compliment_hot',\n",
    "#                              'compliment_more', 'compliment_profile','compliment_cute','compliment_list',\n",
    "#                              'compliment_note', 'compliment_plain', 'compliment_cool','compliment_funny',\n",
    "#                              'compliment_funny', 'compliment_writer','compliment_photos'], axis=1)\n",
    "#     # Renaming column name to avoid conflict with business/review overall star rating\n",
    "#     chunk_user = chunk_user.rename(columns={'average_stars': 'user__average_stars'})\n",
    "#     # Inner merge with  business with reviewers file so only users related to the review remains\n",
    "#     chunk_merged = pd.merge(yelp_merged, chunk_user, on='user_id', how='inner')\n",
    "#     # Show feedback on progress\n",
    "#     print(f\"{chunk_merged.shape[0]} out of {size:,} related users\")\n",
    "#     chunk_merged.to_csv('yelp_data/chunk/chunk_{}.csv'.format(i), index = False)\n",
    "# # # After trimming down the review file, concatenate all relevant data back to one dataframe\n",
    "# # user_merged = pd.concat(chunk_list, ignore_index=True, join='outer', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping users with more than 1 reviewers 1413908-1371908= 42000\n",
    "user_mered= user_merged[user_merged.review_count>1]\n",
    "user_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_merged.to_csv('yelp_data/user_merged.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_merged =pd.read_csv('yelp_data/user_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_merged.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
