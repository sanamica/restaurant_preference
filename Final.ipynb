{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "#nlp\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import re, string\n",
    "import sys\n",
    "import time\n",
    "import collections\n",
    "#nltk.download('stopwords')\n",
    "#model\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "#plotting\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "yelp_compiled = pd.read_csv('Yelp_data/yelp_compiled_new.csv')\n",
    "#yelp_compiled_new =pd.read_csv('yelp_data/yelp_compiled_new.csv')\n",
    "yelp_compiled_tract = pd.read_csv('Yelp_data/yelp_compiled_tract.csv')\n",
    "#mapping\n",
    "vegas_geo = pd.read_csv('Yelp_data/vegas_geo.to_csv')\n",
    "#mapbox access\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoiYW5hbWlrYTEyMyIsImEiOiJja2Fpb3dycmgwMnJhMnJuc213YnA4emlrIn0.b_ToBPcogxVFLkqiaI9DmA\")\n",
    "vegas_geo['review_score'] = vegas_geo['review_count']*vegas_geo['stars']\n",
    "vegas_ranked = vegas_geo.sort_values(by=['review_score','price_range'], ascending=[False,True])\n",
    "#NLP\n",
    "user_merged = pd.read_csv('Yelp_data//user_merged.csv')\n",
    "user_merged_high = user_merged[user_merged['income_range']==2]\n",
    "user_merged_low = user_merged[user_merged['income_range']==0]\n",
    "high_bad_review = user_merged_high[(user_merged_high.review_stars <= 2 )]\n",
    "high_good_review = user_merged_high[(user_merged_high.stars >= 4)]\n",
    "badreviews_only = high_bad_review.text\n",
    "goodreviews_only = high_good_review.text\n",
    "low_bad_review = user_merged_low[(user_merged_low.review_stars <= 2 )]\n",
    "low_good_review = user_merged_low[(user_merged_low.stars >= 4)]\n",
    "low_badreviews_only = low_bad_review.text\n",
    "low_goodreviews_only = low_good_review.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for recomender\n",
    "\n",
    "#kmean\n",
    "geo = vegas_geo[['longitude','latitude']]\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++')\n",
    "kmeans.fit(geo)   # compute kmeans\n",
    "y = kmeans.labels_ #labels of each point\n",
    "#recomender\n",
    "def recommender(df, longitude, latitude):\n",
    "    # Predict the cluster for long and lat provided\n",
    "    cluster = kmeans.predict(np.array([longitude,latitude]).reshape(1,-1))[0]\n",
    "    print(cluster)\n",
    "   \n",
    "    # Get the best restaurant in this cluster\n",
    "    return  df[df['cluster']==cluster].iloc[0:5][['name', 'address', 'category','price_range', 'stars','income_range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for word cloud\n",
    "def tokenize(s):\n",
    "    \"\"\"Convert string to lowercase and split into words (ignoring\n",
    "    punctuation), returning list of words.\n",
    "    \"\"\"\n",
    "    word_list = re.findall(r'\\w+', s.lower())\n",
    "    filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    return filtered_words\n",
    "def count_ngrams(lines, min_length=2, max_length=4):\n",
    "    \"\"\"Iterate through given lines iterator (file object or list of\n",
    "    lines) and return n-gram frequencies. The return value is a dict\n",
    "    mapping the length of the n-gram to a collections.Counter\n",
    "    object of n-gram tuple and number of times that n-gram occurred.\n",
    "    Returned dict includes n-grams of length min_length to max_length.\n",
    "    \"\"\"\n",
    "    lengths = range(min_length, max_length + 1)\n",
    "    ngrams = {length: collections.Counter() for length in lengths}\n",
    "    queue = collections.deque(maxlen=max_length)\n",
    "# Helper function to add n-grams at start of current queue to dict\n",
    "    def add_queue():\n",
    "        current = tuple(queue)\n",
    "        for length in lengths:\n",
    "            if len(current) >= length:\n",
    "                ngrams[length][current[:length]] += 1\n",
    "# Loop through all lines and words and add n-grams to dict\n",
    "    for line in lines:\n",
    "        for word in tokenize(line):\n",
    "            queue.append(word)\n",
    "            if len(queue) >= max_length:\n",
    "                add_queue()\n",
    "# Make sure we get the n-grams at the tail end of the queue\n",
    "    while len(queue) > min_length:\n",
    "        queue.popleft()\n",
    "        add_queue()\n",
    "    return ngrams\n",
    "def print_most_frequent(ngrams, num=10):\n",
    "    \"\"\"Print num most common n-grams of each length in n-grams dict.\"\"\"\n",
    "    for n in sorted(ngrams):\n",
    "        print('----- {} most common {}-word phrase -----'.format(num, n))\n",
    "        for gram, count in ngrams[n].most_common(num):\n",
    "            print('{0}: {1}'.format(' '.join(gram), count))\n",
    "        print('')\n",
    "def print_word_cloud(ngrams, num=5):\n",
    "    \"\"\"Print word cloud image plot \"\"\"\n",
    "    words = []\n",
    "    for n in sorted(ngrams):\n",
    "        for gram, count in ngrams[n].most_common(num):\n",
    "            s = ' '.join(gram)\n",
    "            words.append(s)\n",
    "            \n",
    "    cloud = WordCloud(width=1440, height= 1080,max_words= 200).generate(' '.join(words))\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(cloud)\n",
    "    plt.axis('off');\n",
    "    plt.show()\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_reviewed_high = yelp_compiled[yelp_compiled['income_range']==2\n",
    "Categories={}\n",
    "for cat in yelp_compiled.new_categories.values:\n",
    "    all_categories= cat.split(\",\")\n",
    "    for x in all_categories:\n",
    "        try :\n",
    "            Categories[x] =Categories[x]+1\n",
    "        except:\n",
    "            Categories[x]=1\n",
    "top_categories = pd.DataFrame.from_dict(data= Categories,orient=\"index\")\n",
    "top_categories.reset_index(inplace=True)\n",
    "top_categories.columns = ['Category', 'Count']\n",
    "#Plotting\n",
    "#stripping white space in front of words in column and getting dummy\n",
    "top_categories['Category'] = top_categories['Category'].str.lstrip()\n",
    "#yelp_compiled[\"new_categories\"] = yelp_compiled['new_categories'].str.lstrip()\n",
    "# Top ten restaurant in high\n",
    "income_high = pd.read_csv('Yelp_data/income_high')\n",
    "Categories={}\n",
    "for cat in income_high.new_categories.values:\n",
    "    all_categories= cat.split(\",\")\n",
    "    for x in all_categories:\n",
    "        try :\n",
    "            Categories[x] =Categories[x]+1\n",
    "        except:\n",
    "            Categories[x]=1\n",
    "categories_high = pd.DataFrame.from_dict(data= Categories,orient=\"index\")\n",
    "categories_high.reset_index(inplace=True)\n",
    "categories_high.columns = ['Category', 'Count']\n",
    "#stripping white space in front of words in column and getting dummy\n",
    "categories_high['Category'] = categories_high['Category'].str.lstrip()\n",
    "#Top tenlower class\n",
    "income_low = pd.read_csv('Yelp_data/income_low')\n",
    "#income_low = yelp_compiled[yelp_compiled['income_range']=='0']\n",
    "Categories={}\n",
    "for cat in income_low.new_categories.values:\n",
    "    all_categories= cat.split(\",\")\n",
    "    for x in all_categories:\n",
    "        try :\n",
    "            Categories[x] =Categories[x]+1\n",
    "        except:\n",
    "            Categories[x]=1\n",
    "categories_low = pd.DataFrame.from_dict(data= Categories,orient=\"index\")\n",
    "categories_low.reset_index(inplace=True)\n",
    "categories_low.columns = ['Category', 'Count']\n",
    "#categories_low.sort_values(by ='occurance', ascending =False).head(20).plot.bar(x='category', y ='occurance');\n",
    "#stripping white space in front of words in column and getting dummy\n",
    "categories_low['Category'] = categories_low['Category'].str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.distplot(yelp_compiled.median_income)\n",
    "plt.title(\"Median Income Distribution\", fontsize=15)\n",
    "plt.xlabel('Median Income', fontsize =15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data =yelp_compiled.income_range.value_counts()\n",
    "plt.figure(figsize=(10,7))\n",
    "fig, ax = plt.subplots(figsize = (9,7))\n",
    "sns.boxplot(x = 'income_range', y = 'median_income', data = yelp_compiled)\n",
    "plt.title(\"Median Income Ranges\", fontsize=15)\n",
    "plt.xlabel(\"Income Range\", fontsize = 15)\n",
    "plt.ylabel(\"Median Income\",fontsize =15);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of stars\n",
    "g = sns.catplot(x=\"stars\", col=\"income_range\",\n",
    "                data=yelp_compiled, kind=\"count\",\n",
    "                height= 5, aspect=.9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "categories_sorted =top_categories.sort_values(by ='Count', ascending =False).head(20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='Category',y='Count',data= categories_sorted) \n",
    "plt.title(\"Top Ten Restaurant Categories \", fontsize=15)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\",fontsize =15)\n",
    "plt.xticks(\n",
    "    rotation= 90, \n",
    "    horizontalalignment='center',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large')\n",
    "plt.tight_layout();\n",
    "# top_categories.sort_values(by ='Count', ascending =False).head(20).plot.bar(x='Category', y ='Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "categories_sorted_h =categories_high.sort_values(by ='Count', ascending =False).head(20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='Category',y='Count',data= categories_sorted_h) \n",
    "plt.title(\"Top Ten Restaurant Categories in High Income Group \", fontsize=15)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\",fontsize =15)\n",
    "plt.xticks(\n",
    "    rotation= 90, \n",
    "    horizontalalignment='center',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large')\n",
    "plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "categories_sorted_l =categories_low.sort_values(by ='Count', ascending =False).head(20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='Category',y='Count',data= categories_sorted_l) \n",
    "plt.title(\"Top Ten Restaurant Categories in Low Income Group\", fontsize=15)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Count\",fontsize =15)\n",
    "plt.xticks(\n",
    "    rotation= 90, \n",
    "    horizontalalignment='center',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highly Reviewed restaurant in high income\n",
    "income_high_res =income_high.sort_values(by = ['review_count','stars'], ascending =False).head(20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='name',y= 'stars',data= income_high_res)\n",
    "plt.title(\"Highly Reviewed Restaurant in High Income \", fontsize=15)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Stars\",fontsize =15)\n",
    "plt.xticks(\n",
    "    rotation= 90, \n",
    "    horizontalalignment='center',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in low\n",
    "income_low_res =income_low.sort_values(by = ['review_count','stars'], ascending =False).head(20)\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x='name',y= 'stars',data= income_low_res)\n",
    "plt.title(\"Highly Reviewed Restaurant in Low Income \", fontsize=15)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Stars\",fontsize =15)\n",
    "plt.xticks(\n",
    "    rotation= 90, \n",
    "    horizontalalignment='center',\n",
    "    fontweight='light',\n",
    "    fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Highly_reviewed', dpi = 250);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density of restaurants based upon Ambience\n",
    "from ipywidgets import interact\n",
    "@interact(y = ['restaurant_density', 'romantic', 'intimate', 'touristy', 'hipster', 'divey', 'classy', 'trendy', 'upscale', 'casual'])\n",
    "def make_scatter(y):\n",
    "    yelp_compiled_tract.plot(kind = 'scatter', x = 'median_income', y = y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_compiled_tract[yelp_compiled_tract['restaurant_density']> 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "@interact(y = [ 'american',\n",
    " 'asian_fusion', 'bakeries', 'barbeque', 'bars', 'beer', 'breakfast_&_brunch', 'buffets', 'burgers', 'cafes', 'caterers', 'chicken_wings', 'chinese',\n",
    " 'cocktail_bars', 'coffee_&_tea', 'delis', 'desserts', 'diners', 'fast_food', 'italian', 'japanese', 'juice_bars_&_smoothies', 'lounges',\n",
    " 'mexican', 'nightlife', 'pizza', 'pubs', 'salad', 'sandwiches', 'seafood', 'soup', 'specialty_food', 'sports_bars', 'steakhouses', 'sushi_bars',\n",
    " 'thai', 'vegan', 'vegetarian', 'wine_&_spirits', 'wine_bars', 'ethnic_food'])\n",
    "def make_scatter(y):\n",
    "    yelp_compiled_tract.plot(kind = 'scatter', x = 'median_income', y = y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location based Recomender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.scatter_mapbox(vegas_geo, lat=\"latitude\", lon=\"longitude\", color=\"cluster\", \n",
    "                  hover_data= ['name', 'census_tract', 'income_range','category'], width=1200, height=800 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender(vegas_ranked,-115.061403,  36.131594)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender(vegas_ranked,-115.240092,  36.2144713)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender(vegas_ranked,-115.172342,  36.103530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = yelp_compiled_tract.columns.drop([ 'city', 'census_tract', 'median_income', 'income_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= yelp_compiled_tract[feature_cols]\n",
    "y= yelp_compiled_tract['income_range']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size =0.3, random_state = 321)\n",
    "scaler = StandardScaler()\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "clf= LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf.predict_proba(X_train)\n",
    "preds = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "# Print Classification report to look at precision, recall and f1 score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Over sampler\n",
    "oversampler = RandomOverSampler(random_state = 321)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix and plot the heatmap \n",
    "log_mod_cm = confusion_matrix(y_test,y_pred)\n",
    "print(log_mod_cm)\n",
    "# plot confusion matrix\n",
    "sns.set(rc={'figure.figsize':(8,6)}, font_scale=2)\n",
    "ax= plt.subplot()\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt='g', linewidths=.5, cmap='coolwarm'); #annot=True to annotate cells\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature Importance\n",
    "full_col_names = list(feature_cols.values)\n",
    "features = pd.DataFrame(clf.coef_[0], index =feature_cols.values, columns = ['importance']).sort_values('importance', ascending=False)\n",
    "features = features.reset_index().rename(columns = ({'index':'feature'}))\n",
    "# selecting top 15 and bottom 15 \n",
    "top15 = features.head(15)\n",
    "bottom15 =features.tail(15)\n",
    "top_features = pd.concat([top15,bottom15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the classifiers to visualize the class imbalance. \n",
    "sns.set(rc={'figure.figsize':(15,8)}, font_scale=1.6)\n",
    "sns.set_style(\"ticks\")\n",
    "sns.barplot(top_features.importance, top_features.feature, alpha=1)\n",
    "plt.title('Logmod Feature Importance', fontsize = 20)\n",
    "plt.ylabel('Features', fontsize=20)\n",
    "plt.xlabel('Feature Importance', fontsize=20)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(yelp_compiled_tract, x=\"stars\", y=\"median_income\", color =\"city\", trendline=\"ols\", labels ={ \"wins\":'Wins Percentage',\"total_salary\": \"Salary per Team\",\"year_bins\": \"Year Range\"},\n",
    "                 title =\"Corelation Between Stars and Median Income \")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_badreviews = count_ngrams(badreviews_only,max_length=3)\n",
    "%time\n",
    "print_word_cloud(most_frequent_badreviews, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_frequent(most_frequent_badreviews, num= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_goodreviews = count_ngrams(goodreviews_only,max_length=3)\n",
    "print_word_cloud(most_frequent_goodreviews, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_frequent(most_frequent_goodreviews, num= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_low_goodreviews = count_ngrams(low_goodreviews_only,max_length=3)\n",
    "print_word_cloud(most_frequent_low_goodreviews, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_frequent(most_frequent_low_goodreviews, num= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter(yelp_compiled_tract, x=\"stars\", y ='median_income', facet_col = \"income_bins\",color =\"city\")\n",
    "# #                 title =\"Total Salary Over The Years : 2000 - 2016\")\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
